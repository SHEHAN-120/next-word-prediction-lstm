{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3d29pPooyNsmPoWLooNqF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SHEHAN-120/next-word-prediction-lstm/blob/main/nlp_text_generator_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TREVGdHmTMiX"
      },
      "outputs": [],
      "source": [
        "text=\"\"\"Data plays a vital role in our everyday life.\n",
        "Directly or indirectly, for daily life decisions, we depend on some data, be it choosing a novel to read from a list of books,buying a thing after considering the budget, and so on.\n",
        "Have you ever imagined searching for something on Google or Yahoo generates a lot of data?\n",
        "This data is essential to analyze user experiences.\n",
        "Getting recommendations on various e-commerce websites after buying a product and tracking parcels during delivery are part of Data Analytics which involves analyzing the raw data to make informed decisions.\n",
        "But this raw data does not help make decisions if it has some redundancy, inconsistency, or inaccuracy.\n",
        "Therefore, this data needs to be cleaned before considering for analysis.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense\n"
      ],
      "metadata": {
        "id": "nGCD7iVhUWZi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer()"
      ],
      "metadata": {
        "id": "Qabz5wEwUiG7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([text])"
      ],
      "metadata": {
        "id": "pcQumn2YUnfw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCgXV5jlUtds",
        "outputId": "c47f4124-4a02-4742-cb2f-2b0bb5e1fca7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in text.split('\\n'):\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6uNxu5ZWOU-",
        "outputId": "7fb2d828-5b73-4b31-e810-a95c88885813"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data plays a vital role in our everyday life. \n",
            "Directly or indirectly, for daily life decisions, we depend on some data, be it choosing a novel to read from a list of books,buying a thing after considering the budget, and so on. \n",
            "Have you ever imagined searching for something on Google or Yahoo generates a lot of data? \n",
            "This data is essential to analyze user experiences. \n",
            "Getting recommendations on various e-commerce websites after buying a product and tracking parcels during delivery are part of Data Analytics which involves analyzing the raw data to make informed decisions. \n",
            "But this raw data does not help make decisions if it has some redundancy, inconsistency, or inaccuracy. \n",
            "Therefore, this data needs to be cleaned before considering for analysis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in text.split('\\n'):\n",
        "  print(tokenizer.texts_to_sequences([sentence])[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bpr9Z2_Uzod",
        "outputId": "5a0e5b41-cc54-44c5-d117-11022aabe1ae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 21, 2, 22, 23, 24, 25, 26, 10]\n",
            "[27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2, 33, 4, 34, 35, 2, 36, 8, 37, 14, 2, 38, 15, 16, 17, 39, 18, 40, 3]\n",
            "[41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48, 49, 2, 50, 8, 1]\n",
            "[9, 1, 51, 52, 4, 53, 54, 55]\n",
            "[56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65, 66, 67, 68, 8, 1, 69, 70, 71, 72, 17, 19, 1, 4, 20, 73, 7]\n",
            "[74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79, 11, 80, 81, 5, 82]\n",
            "[83, 9, 1, 84, 4, 12, 85, 86, 16, 6, 87]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence=[]\n",
        "for sentence in text.split('\\n'):\n",
        "  tokenized_sentence=tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequence.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "N62KZO2SWCS9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tx6C0RVPXpn0",
        "outputId": "47d1594b-2c57-40da-b81f-a6a7fde9eb9d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 21],\n",
              " [1, 21, 2],\n",
              " [1, 21, 2, 22],\n",
              " [1, 21, 2, 22, 23],\n",
              " [1, 21, 2, 22, 23, 24],\n",
              " [1, 21, 2, 22, 23, 24, 25],\n",
              " [1, 21, 2, 22, 23, 24, 25, 26],\n",
              " [1, 21, 2, 22, 23, 24, 25, 26, 10],\n",
              " [27, 5],\n",
              " [27, 5, 28],\n",
              " [27, 5, 28, 6],\n",
              " [27, 5, 28, 6, 29],\n",
              " [27, 5, 28, 6, 29, 10],\n",
              " [27, 5, 28, 6, 29, 10, 7],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2, 33],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2, 33, 4],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2, 33, 4, 34],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2, 33, 4, 34, 35],\n",
              " [27, 5, 28, 6, 29, 10, 7, 30, 31, 3, 11, 1, 12, 13, 32, 2, 33, 4, 34, 35, 2],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15,\n",
              "  16],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15,\n",
              "  16,\n",
              "  17],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  39],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  39,\n",
              "  18],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  39,\n",
              "  18,\n",
              "  40],\n",
              " [27,\n",
              "  5,\n",
              "  28,\n",
              "  6,\n",
              "  29,\n",
              "  10,\n",
              "  7,\n",
              "  30,\n",
              "  31,\n",
              "  3,\n",
              "  11,\n",
              "  1,\n",
              "  12,\n",
              "  13,\n",
              "  32,\n",
              "  2,\n",
              "  33,\n",
              "  4,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  36,\n",
              "  8,\n",
              "  37,\n",
              "  14,\n",
              "  2,\n",
              "  38,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  39,\n",
              "  18,\n",
              "  40,\n",
              "  3],\n",
              " [41, 42],\n",
              " [41, 42, 43],\n",
              " [41, 42, 43, 44],\n",
              " [41, 42, 43, 44, 45],\n",
              " [41, 42, 43, 44, 45, 6],\n",
              " [41, 42, 43, 44, 45, 6, 46],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48, 49],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48, 49, 2],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48, 49, 2, 50],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48, 49, 2, 50, 8],\n",
              " [41, 42, 43, 44, 45, 6, 46, 3, 47, 5, 48, 49, 2, 50, 8, 1],\n",
              " [9, 1],\n",
              " [9, 1, 51],\n",
              " [9, 1, 51, 52],\n",
              " [9, 1, 51, 52, 4],\n",
              " [9, 1, 51, 52, 4, 53],\n",
              " [9, 1, 51, 52, 4, 53, 54],\n",
              " [9, 1, 51, 52, 4, 53, 54, 55],\n",
              " [56, 57],\n",
              " [56, 57, 3],\n",
              " [56, 57, 3, 58],\n",
              " [56, 57, 3, 58, 59],\n",
              " [56, 57, 3, 58, 59, 60],\n",
              " [56, 57, 3, 58, 59, 60, 61],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65, 66],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65, 66, 67],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65, 66, 67, 68],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65, 66, 67, 68, 8],\n",
              " [56, 57, 3, 58, 59, 60, 61, 15, 14, 2, 62, 18, 63, 64, 65, 66, 67, 68, 8, 1],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17,\n",
              "  19],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17,\n",
              "  19,\n",
              "  1],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17,\n",
              "  19,\n",
              "  1,\n",
              "  4],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17,\n",
              "  19,\n",
              "  1,\n",
              "  4,\n",
              "  20],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17,\n",
              "  19,\n",
              "  1,\n",
              "  4,\n",
              "  20,\n",
              "  73],\n",
              " [56,\n",
              "  57,\n",
              "  3,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  15,\n",
              "  14,\n",
              "  2,\n",
              "  62,\n",
              "  18,\n",
              "  63,\n",
              "  64,\n",
              "  65,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  8,\n",
              "  1,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  17,\n",
              "  19,\n",
              "  1,\n",
              "  4,\n",
              "  20,\n",
              "  73,\n",
              "  7],\n",
              " [74, 9],\n",
              " [74, 9, 19],\n",
              " [74, 9, 19, 1],\n",
              " [74, 9, 19, 1, 75],\n",
              " [74, 9, 19, 1, 75, 76],\n",
              " [74, 9, 19, 1, 75, 76, 77],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79, 11],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79, 11, 80],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79, 11, 80, 81],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79, 11, 80, 81, 5],\n",
              " [74, 9, 19, 1, 75, 76, 77, 20, 7, 78, 13, 79, 11, 80, 81, 5, 82],\n",
              " [83, 9],\n",
              " [83, 9, 1],\n",
              " [83, 9, 1, 84],\n",
              " [83, 9, 1, 84, 4],\n",
              " [83, 9, 1, 84, 4, 12],\n",
              " [83, 9, 1, 84, 4, 12, 85],\n",
              " [83, 9, 1, 84, 4, 12, 85, 86],\n",
              " [83, 9, 1, 84, 4, 12, 85, 86, 16],\n",
              " [83, 9, 1, 84, 4, 12, 85, 86, 16, 6],\n",
              " [83, 9, 1, 84, 4, 12, 85, 86, 16, 6, 87]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=max([len(x) for x in input_sequence])"
      ],
      "metadata": {
        "id": "qzjV7lBEX6P_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXD6McK4Yx8e",
        "outputId": "7562a4ba-fbd7-41f2-8b74-5936217f21bd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences=pad_sequences(input_sequence,maxlen=max_len,padding='pre')"
      ],
      "metadata": {
        "id": "QTt9nkeqYy6l"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhZDEb7EZf_1",
        "outputId": "b3cbab7e-2980-444e-cffe-8f4ea5a5563e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  1, 21],\n",
              "       [ 0,  0,  0, ...,  1, 21,  2],\n",
              "       [ 0,  0,  0, ..., 21,  2, 22],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 85, 86, 16],\n",
              "       [ 0,  0,  0, ..., 86, 16,  6],\n",
              "       [ 0,  0,  0, ..., 16,  6, 87]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=padded_input_sequences[:,:-1]\n",
        "y=padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "uREtDJTdZknv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3k8Rp-JaTCC",
        "outputId": "842488c7-9469-4d98-8668-4fb35374d9cb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  0,  1],\n",
              "       [ 0,  0,  0, ...,  0,  1, 21],\n",
              "       [ 0,  0,  0, ...,  1, 21,  2],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 12, 85, 86],\n",
              "       [ 0,  0,  0, ..., 85, 86, 16],\n",
              "       [ 0,  0,  0, ..., 86, 16,  6]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvB4Or9MaVqx",
        "outputId": "f658e6f7-d40d-4549-a3ee-ff8158f85f9f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([21,  2, 22, 23, 24, 25, 26, 10,  5, 28,  6, 29, 10,  7, 30, 31,  3,\n",
              "       11,  1, 12, 13, 32,  2, 33,  4, 34, 35,  2, 36,  8, 37, 14,  2, 38,\n",
              "       15, 16, 17, 39, 18, 40,  3, 42, 43, 44, 45,  6, 46,  3, 47,  5, 48,\n",
              "       49,  2, 50,  8,  1,  1, 51, 52,  4, 53, 54, 55, 57,  3, 58, 59, 60,\n",
              "       61, 15, 14,  2, 62, 18, 63, 64, 65, 66, 67, 68,  8,  1, 69, 70, 71,\n",
              "       72, 17, 19,  1,  4, 20, 73,  7,  9, 19,  1, 75, 76, 77, 20,  7, 78,\n",
              "       13, 79, 11, 80, 81,  5, 82,  9,  1, 84,  4, 12, 85, 86, 16,  6, 87],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y_7OiL0bQYR",
        "outputId": "6cebc3c2-430c-4f5d-a71c-9636377ddfa8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': 1,\n",
              " 'a': 2,\n",
              " 'on': 3,\n",
              " 'to': 4,\n",
              " 'or': 5,\n",
              " 'for': 6,\n",
              " 'decisions': 7,\n",
              " 'of': 8,\n",
              " 'this': 9,\n",
              " 'life': 10,\n",
              " 'some': 11,\n",
              " 'be': 12,\n",
              " 'it': 13,\n",
              " 'buying': 14,\n",
              " 'after': 15,\n",
              " 'considering': 16,\n",
              " 'the': 17,\n",
              " 'and': 18,\n",
              " 'raw': 19,\n",
              " 'make': 20,\n",
              " 'plays': 21,\n",
              " 'vital': 22,\n",
              " 'role': 23,\n",
              " 'in': 24,\n",
              " 'our': 25,\n",
              " 'everyday': 26,\n",
              " 'directly': 27,\n",
              " 'indirectly': 28,\n",
              " 'daily': 29,\n",
              " 'we': 30,\n",
              " 'depend': 31,\n",
              " 'choosing': 32,\n",
              " 'novel': 33,\n",
              " 'read': 34,\n",
              " 'from': 35,\n",
              " 'list': 36,\n",
              " 'books': 37,\n",
              " 'thing': 38,\n",
              " 'budget': 39,\n",
              " 'so': 40,\n",
              " 'have': 41,\n",
              " 'you': 42,\n",
              " 'ever': 43,\n",
              " 'imagined': 44,\n",
              " 'searching': 45,\n",
              " 'something': 46,\n",
              " 'google': 47,\n",
              " 'yahoo': 48,\n",
              " 'generates': 49,\n",
              " 'lot': 50,\n",
              " 'is': 51,\n",
              " 'essential': 52,\n",
              " 'analyze': 53,\n",
              " 'user': 54,\n",
              " 'experiences': 55,\n",
              " 'getting': 56,\n",
              " 'recommendations': 57,\n",
              " 'various': 58,\n",
              " 'e': 59,\n",
              " 'commerce': 60,\n",
              " 'websites': 61,\n",
              " 'product': 62,\n",
              " 'tracking': 63,\n",
              " 'parcels': 64,\n",
              " 'during': 65,\n",
              " 'delivery': 66,\n",
              " 'are': 67,\n",
              " 'part': 68,\n",
              " 'analytics': 69,\n",
              " 'which': 70,\n",
              " 'involves': 71,\n",
              " 'analyzing': 72,\n",
              " 'informed': 73,\n",
              " 'but': 74,\n",
              " 'does': 75,\n",
              " 'not': 76,\n",
              " 'help': 77,\n",
              " 'if': 78,\n",
              " 'has': 79,\n",
              " 'redundancy': 80,\n",
              " 'inconsistency': 81,\n",
              " 'inaccuracy': 82,\n",
              " 'therefore': 83,\n",
              " 'needs': 84,\n",
              " 'cleaned': 85,\n",
              " 'before': 86,\n",
              " 'analysis': 87}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=to_categorical(y,num_classes=88)"
      ],
      "metadata": {
        "id": "Ll_wyh0abUdG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk9VHf_9bvbV",
        "outputId": "2127e236-29fb-4472-f672-1ef2f554d854"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrGdPqsZbzdg",
        "outputId": "bdf4a333-360d-4e8e-d910-6f74e815f4bb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119, 88)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM_u8L7qb31l",
        "outputId": "2813e02b-97bb-42f9-86e5-c03bfa19761f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building"
      ],
      "metadata": {
        "id": "2VDl3Mu4cdPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(88,100,input_length=33))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(88,activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwe0sN7ncf5f",
        "outputId": "6ab5a23a-e1ba-4e38-ff48-e8287d5964aa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "gsOXN97HefuS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "bK02_dXWe0I4",
        "outputId": "f4f72a55-e4a8-4f71-c8a4-6f98fb817b59"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPsr7bcUg5is",
        "outputId": "4fd01fa4-ed2c-4365-95c5-a780309e2fa0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIcTcrasg8y6",
        "outputId": "4b395854-92c5-4ee3-9b86-5e0744e23ee3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119, 88)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfYOi_mpg-Ud",
        "outputId": "24e9b4ab-269f-4f83-b484-9c9e5ee0f178"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.0259 - loss: 4.4761\n",
            "Epoch 2/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.1055 - loss: 4.4578\n",
            "Epoch 3/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.0644 - loss: 4.4244\n",
            "Epoch 4/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.0496 - loss: 4.3450\n",
            "Epoch 5/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.0592 - loss: 4.3008\n",
            "Epoch 6/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.0717 - loss: 4.2312\n",
            "Epoch 7/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.0644 - loss: 4.1676\n",
            "Epoch 8/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.0696 - loss: 4.1356\n",
            "Epoch 9/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.0675 - loss: 4.0788\n",
            "Epoch 10/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.0402 - loss: 4.0314\n",
            "Epoch 11/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.0644 - loss: 3.9355\n",
            "Epoch 12/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.0605 - loss: 3.8002\n",
            "Epoch 13/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.0903 - loss: 3.7457\n",
            "Epoch 14/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - accuracy: 0.1481 - loss: 3.6093\n",
            "Epoch 15/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.0932 - loss: 3.5719\n",
            "Epoch 16/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.1052 - loss: 3.5413\n",
            "Epoch 17/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.1423 - loss: 3.4089\n",
            "Epoch 18/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.1173 - loss: 3.3190\n",
            "Epoch 19/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.1338 - loss: 3.1841\n",
            "Epoch 20/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.1662 - loss: 3.1327\n",
            "Epoch 21/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.1812 - loss: 3.0961\n",
            "Epoch 22/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.1917 - loss: 2.9432\n",
            "Epoch 23/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2098 - loss: 2.9119\n",
            "Epoch 24/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.2059 - loss: 2.8407\n",
            "Epoch 25/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.2774 - loss: 2.6365\n",
            "Epoch 26/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.3408 - loss: 2.5923\n",
            "Epoch 27/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2478 - loss: 2.5346\n",
            "Epoch 28/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.3539 - loss: 2.4896\n",
            "Epoch 29/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.3914 - loss: 2.3561\n",
            "Epoch 30/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.3769 - loss: 2.2613\n",
            "Epoch 31/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.4624 - loss: 2.2254\n",
            "Epoch 32/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4464 - loss: 2.1188\n",
            "Epoch 33/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4740 - loss: 2.0968\n",
            "Epoch 34/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5597 - loss: 1.9821\n",
            "Epoch 35/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5679 - loss: 1.9746\n",
            "Epoch 36/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5948 - loss: 1.8707\n",
            "Epoch 37/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6201 - loss: 1.8398\n",
            "Epoch 38/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6700 - loss: 1.7923\n",
            "Epoch 39/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6596 - loss: 1.7323\n",
            "Epoch 40/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.7046 - loss: 1.6841\n",
            "Epoch 41/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.7576 - loss: 1.6364 \n",
            "Epoch 42/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7422 - loss: 1.5688\n",
            "Epoch 43/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7725 - loss: 1.5541\n",
            "Epoch 44/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8222 - loss: 1.4615\n",
            "Epoch 45/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7850 - loss: 1.4603\n",
            "Epoch 46/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7743 - loss: 1.4664\n",
            "Epoch 47/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8292 - loss: 1.3802\n",
            "Epoch 48/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8390 - loss: 1.3295\n",
            "Epoch 49/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8385 - loss: 1.3499\n",
            "Epoch 50/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8507 - loss: 1.2863\n",
            "Epoch 51/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8881 - loss: 1.2322\n",
            "Epoch 52/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.8614 - loss: 1.2377\n",
            "Epoch 53/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.8756 - loss: 1.2099\n",
            "Epoch 54/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.9011 - loss: 1.1544\n",
            "Epoch 55/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9320 - loss: 1.0907\n",
            "Epoch 56/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9663 - loss: 1.0736\n",
            "Epoch 57/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9148 - loss: 1.0771\n",
            "Epoch 58/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9644 - loss: 1.0346\n",
            "Epoch 59/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9231 - loss: 1.0608\n",
            "Epoch 60/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9764 - loss: 0.9871\n",
            "Epoch 61/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9860 - loss: 0.9703\n",
            "Epoch 62/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9805 - loss: 0.9134\n",
            "Epoch 63/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9712 - loss: 0.9555\n",
            "Epoch 64/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9712 - loss: 0.8808\n",
            "Epoch 65/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9766 - loss: 0.9017\n",
            "Epoch 66/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9751 - loss: 0.8354\n",
            "Epoch 67/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9761 - loss: 0.8811\n",
            "Epoch 68/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9766 - loss: 0.8406\n",
            "Epoch 69/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9933 - loss: 0.7665\n",
            "Epoch 70/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9878 - loss: 0.7772\n",
            "Epoch 71/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9860 - loss: 0.7773\n",
            "Epoch 72/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9697 - loss: 0.7604\n",
            "Epoch 73/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9556 - loss: 0.7643\n",
            "Epoch 74/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9805 - loss: 0.7309\n",
            "Epoch 75/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8787 - loss: 0.8208\n",
            "Epoch 76/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9016 - loss: 0.8186\n",
            "Epoch 77/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9442 - loss: 0.7625\n",
            "Epoch 78/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9818 - loss: 0.6927\n",
            "Epoch 79/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9946 - loss: 0.6763\n",
            "Epoch 80/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9966 - loss: 0.6269\n",
            "Epoch 81/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9914 - loss: 0.5984\n",
            "Epoch 82/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9914 - loss: 0.5909\n",
            "Epoch 83/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.9946 - loss: 0.5772\n",
            "Epoch 84/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.9852 - loss: 0.5874\n",
            "Epoch 85/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - accuracy: 0.9966 - loss: 0.5397\n",
            "Epoch 86/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9933 - loss: 0.5216\n",
            "Epoch 87/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.9966 - loss: 0.5297\n",
            "Epoch 88/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9852 - loss: 0.5117\n",
            "Epoch 89/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.9852 - loss: 0.5063\n",
            "Epoch 90/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9914 - loss: 0.4787\n",
            "Epoch 91/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - accuracy: 0.9914 - loss: 0.4916\n",
            "Epoch 92/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9852 - loss: 0.4692\n",
            "Epoch 93/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9914 - loss: 0.4644\n",
            "Epoch 94/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9852 - loss: 0.4399\n",
            "Epoch 95/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9946 - loss: 0.4212\n",
            "Epoch 96/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9946 - loss: 0.4043\n",
            "Epoch 97/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9966 - loss: 0.4120\n",
            "Epoch 98/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9946 - loss: 0.3873\n",
            "Epoch 99/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9914 - loss: 0.3950\n",
            "Epoch 100/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9966 - loss: 0.3773\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x785713521850>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model"
      ],
      "metadata": {
        "id": "JSvLbs63hXiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_1=\"Data\"\n",
        "\n",
        "token_text=tokenizer.texts_to_sequences([text_1])[0]\n",
        "padded_text=pad_sequences([token_text],maxlen=33,padding='pre')\n",
        "model.predict(padded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbV6sCaLhavB",
        "outputId": "a1eb70bf-53ef-4908-f21d-d2b8cc01410c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.03822858e-05, 8.70685373e-03, 2.14119423e-02, 1.29598321e-03,\n",
              "        4.77626594e-03, 4.34044562e-02, 2.48853699e-03, 4.06207429e-04,\n",
              "        1.10075453e-04, 4.34377268e-02, 7.81444483e-04, 2.90784646e-05,\n",
              "        3.27301421e-03, 1.89945604e-05, 4.03067417e-04, 2.08943762e-04,\n",
              "        2.44686526e-04, 3.65571672e-04, 3.76881871e-05, 1.55683113e-02,\n",
              "        5.72925142e-04, 5.39237857e-01, 7.59400008e-03, 1.28992950e-03,\n",
              "        6.80851925e-04, 9.59064637e-05, 1.08057022e-04, 1.69702980e-05,\n",
              "        2.01133620e-02, 7.46663602e-04, 4.99130751e-04, 7.16366107e-04,\n",
              "        1.10351146e-04, 7.98654437e-05, 8.02086215e-05, 5.03056472e-05,\n",
              "        3.33509925e-05, 1.03940212e-04, 5.05630669e-05, 8.21109497e-05,\n",
              "        2.74923168e-05, 8.61311310e-06, 4.99895327e-02, 2.02346966e-02,\n",
              "        4.88597574e-03, 2.27926043e-03, 3.76853859e-04, 9.07368012e-05,\n",
              "        1.74072647e-05, 5.33805978e-05, 1.83913493e-04, 1.26479015e-01,\n",
              "        7.01007945e-03, 2.49033299e-04, 1.31269626e-04, 3.49919974e-05,\n",
              "        1.57293489e-05, 9.20494087e-03, 7.96518987e-04, 9.59312136e-04,\n",
              "        1.55371803e-04, 9.55762152e-05, 9.02998217e-05, 1.93834985e-05,\n",
              "        4.92852487e-05, 5.30218131e-06, 1.51556605e-05, 8.25090410e-06,\n",
              "        6.80442608e-05, 6.08431983e-05, 9.91757115e-05, 1.71926469e-04,\n",
              "        3.03991983e-04, 5.72054851e-05, 1.60955733e-05, 4.80781775e-03,\n",
              "        9.40237136e-04, 1.64957033e-04, 5.23545168e-05, 4.18282871e-05,\n",
              "        3.24378234e-05, 3.29106770e-05, 1.31124043e-05, 2.71833724e-05,\n",
              "        4.98281568e-02, 4.25353122e-04, 1.32559464e-04, 1.44956412e-05]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos=np.argmax(model.predict(padded_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAtDG4VAh11F",
        "outputId": "600e7bbb-7af9-4d15-efcf-0f2a55a5916e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4YbXituiyaD",
        "outputId": "78e7188e-1b43-49c9-841f-cc11b6cf5429"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': 1,\n",
              " 'a': 2,\n",
              " 'on': 3,\n",
              " 'to': 4,\n",
              " 'or': 5,\n",
              " 'for': 6,\n",
              " 'decisions': 7,\n",
              " 'of': 8,\n",
              " 'this': 9,\n",
              " 'life': 10,\n",
              " 'some': 11,\n",
              " 'be': 12,\n",
              " 'it': 13,\n",
              " 'buying': 14,\n",
              " 'after': 15,\n",
              " 'considering': 16,\n",
              " 'the': 17,\n",
              " 'and': 18,\n",
              " 'raw': 19,\n",
              " 'make': 20,\n",
              " 'plays': 21,\n",
              " 'vital': 22,\n",
              " 'role': 23,\n",
              " 'in': 24,\n",
              " 'our': 25,\n",
              " 'everyday': 26,\n",
              " 'directly': 27,\n",
              " 'indirectly': 28,\n",
              " 'daily': 29,\n",
              " 'we': 30,\n",
              " 'depend': 31,\n",
              " 'choosing': 32,\n",
              " 'novel': 33,\n",
              " 'read': 34,\n",
              " 'from': 35,\n",
              " 'list': 36,\n",
              " 'books': 37,\n",
              " 'thing': 38,\n",
              " 'budget': 39,\n",
              " 'so': 40,\n",
              " 'have': 41,\n",
              " 'you': 42,\n",
              " 'ever': 43,\n",
              " 'imagined': 44,\n",
              " 'searching': 45,\n",
              " 'something': 46,\n",
              " 'google': 47,\n",
              " 'yahoo': 48,\n",
              " 'generates': 49,\n",
              " 'lot': 50,\n",
              " 'is': 51,\n",
              " 'essential': 52,\n",
              " 'analyze': 53,\n",
              " 'user': 54,\n",
              " 'experiences': 55,\n",
              " 'getting': 56,\n",
              " 'recommendations': 57,\n",
              " 'various': 58,\n",
              " 'e': 59,\n",
              " 'commerce': 60,\n",
              " 'websites': 61,\n",
              " 'product': 62,\n",
              " 'tracking': 63,\n",
              " 'parcels': 64,\n",
              " 'during': 65,\n",
              " 'delivery': 66,\n",
              " 'are': 67,\n",
              " 'part': 68,\n",
              " 'analytics': 69,\n",
              " 'which': 70,\n",
              " 'involves': 71,\n",
              " 'analyzing': 72,\n",
              " 'informed': 73,\n",
              " 'but': 74,\n",
              " 'does': 75,\n",
              " 'not': 76,\n",
              " 'help': 77,\n",
              " 'if': 78,\n",
              " 'has': 79,\n",
              " 'redundancy': 80,\n",
              " 'inconsistency': 81,\n",
              " 'inaccuracy': 82,\n",
              " 'therefore': 83,\n",
              " 'needs': 84,\n",
              " 'cleaned': 85,\n",
              " 'before': 86,\n",
              " 'analysis': 87}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word,index in tokenizer.word_index.items():\n",
        "  if index==pos:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pg7ILQAtjNW0",
        "outputId": "5319ddfe-6080-462d-9baa-99d86977a951"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "plays\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2=\"Data is a vital\"\n",
        "\n",
        "token_text_2=tokenizer.texts_to_sequences([text_2])[0]\n",
        "padded_text_2=pad_sequences([token_text_2],maxlen=33,padding='pre')\n",
        "model.predict(padded_text_2)\n",
        "\n",
        "pos_2=np.argmax(model.predict(padded_text_2))\n",
        "\n",
        "for word,index in tokenizer.word_index.items():\n",
        "  if index==pos_2:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSnG6L7Pjazz",
        "outputId": "4ab30209-ccc5-46b4-e8d1-8b1eaff113c9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "role\n"
          ]
        }
      ]
    }
  ]
}